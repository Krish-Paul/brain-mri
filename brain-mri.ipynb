{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install numpy","metadata":{"id":"2-r8E1rrGskA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing necessary Libraries","metadata":{"id":"FRU-fiF-QAq2"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.optimizers.legacy import Adam\nfrom tensorflow.keras.metrics import F1Score\n\nimport cv2\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom glob import glob\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n","metadata":{"id":"C2Y85OfXO8qe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_width = 256\nimg_height = 256\n\nimages_train = []\n\n# print(mask_files)\ndata_path = '/kaggle/input/lgg-mri-segmentation/kaggle_3m'","metadata":{"id":"_Q-rQrKjYsqQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_files = glob(pathname= data_path+'/*/*_mask*')\nmask_files[:1]","metadata":{"id":"FbVeDKv9YoOZ","outputId":"cbc9b516-d812-467b-a1bb-05e400d75ddc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in mask_files:\n  images_train.append(i.replace('_mask', ''))\nprint(images_train[:5])\n","metadata":{"id":"tYC4iWWpambA","outputId":"9799fae0-a297-4a5b-9083-8575e5fe074c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(images_train)","metadata":{"id":"lWuf8VXEdFVF","outputId":"d8c6ddf0-e739-4ca2-d4c1-2d5dd9bbad24","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization\n\n\nHere are the few samples of the data\n\n","metadata":{"id":"7kZ2icu4diUr"}},{"cell_type":"code","source":"def plot_from_path(rows, columns, img_list_path, mask_list_path):\n  fig = plt.figure( figsize = (12,12))\n  for i in range(1, rows*columns+1):\n    fig.add_subplot(rows,columns, i)\n    img_path = img_list_path[i]\n    mask_path = mask_list_path[i]\n    image = cv2.imread(img_path)\n    image =cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    mask = cv2.imread(mask_path)\n    plt.imshow(image)\n    plt.imshow(mask, alpha = 0.05)\n  plt.show()","metadata":{"id":"rpPCgH9SdovL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_from_path(5,5, images_train, mask_files)","metadata":{"id":"1H97wGMofL_B","outputId":"8eaf6577-9ff3-4c53-a513-e955589f400c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{"id":"-xeQvBX6g3J8"}},{"cell_type":"markdown","source":"### Splitting into test, train and validation\n\n\nWe split the data into train, test and validation datas alloting them 85%, 10% and 5% datas respectively","metadata":{"id":"oXlRU5eQg7el"}},{"cell_type":"code","source":"df = pd.DataFrame( data = {\n    'images_train': images_train,\n    'masks': mask_files\n})\ndf_train, df_test = train_test_split(df, test_size = 0.10)\ndf_train, df_valid = train_test_split(df_train, test_size=0.05)\n\nprint(df_train.shape)\nprint(df_test.shape)\nprint(df_valid.shape)","metadata":{"id":"iBoEAzc4fR_q","outputId":"71106f71-9774-41d7-fd49-c2f4233bb529","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generators, Augmentation, Normalization and Loss Calculator","metadata":{"id":"C2i67BdkjLMD"}},{"cell_type":"code","source":"def train_generator(\n    data_frame,\n    batch_size,\n    augmentation_dict,\n    image_color_mode=\"rgb\",\n    mask_color_mode=\"grayscale\",\n    image_save_prefix=\"image\",\n    mask_save_prefix=\"mask\",\n    save_to_dir=None,\n    target_size=(256, 256),\n    seed=1,\n):\n\n    image_datagen = ImageDataGenerator(**augmentation_dict)\n    mask_datagen = ImageDataGenerator(**augmentation_dict)\n\n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col=\"images_train\",\n        class_mode=None,\n        color_mode=image_color_mode,\n        target_size=target_size,\n        batch_size=batch_size,\n        save_to_dir=save_to_dir,\n        save_prefix=image_save_prefix,\n        seed=seed,\n    )\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col=\"masks\",\n        class_mode=None,\n        color_mode=mask_color_mode,\n        target_size=target_size,\n        batch_size=batch_size,\n        save_to_dir=save_to_dir,\n        save_prefix=mask_save_prefix,\n        seed=seed,\n    )\n\n    train_gen = zip(image_generator, mask_generator)\n\n\n    for (img, mask) in train_gen:\n        img, mask = normalize_data(img, mask)\n        yield (img, mask)","metadata":{"id":"e8qXQmDNhk5n","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_data(img,mask):\n    img = img / 255\n    mask = mask / 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n\n    return (img, mask)","metadata":{"id":"P2kfRrhSjJAX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_coefficients(y_true, y_pred, smooth=100):\n    y_true_flatten = K.flatten(y_true)\n    y_pred_flatten = K.flatten(y_pred)\n\n    intersection = K.sum(y_true_flatten * y_pred_flatten)\n    union = K.sum(y_true_flatten) + K.sum(y_pred_flatten)\n    return (2 * intersection + smooth) / (union + smooth)\n\ndef dice_coefficients_loss(y_true, y_pred, smooth=100):\n    return -dice_coefficients(y_true, y_pred, smooth)\ndef iou(y_true, y_pred, smooth=100):\n    intersection = K.sum(y_true * y_pred)\n    sum = K.sum(y_true + y_pred)\n    iou = (intersection + smooth) / (sum - intersection + smooth)\n    return iou\ndef jaccard_distance(y_true, y_pred):\n    y_true_flatten = K.flatten(y_true)\n    y_pred_flatten = K.flatten(y_pred)\n    return -iou(y_true_flatten, y_pred_flatten)","metadata":{"id":"S0uj9aw7oAVP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining encoder and decoder block","metadata":{"id":"-j2WZz3vp_Td"}},{"cell_type":"code","source":"def encoder_block(inputs, filters):\n    conv = Conv2D(filters, kernel_size = (3,3), padding=\"same\")(inputs)\n    bn = Activation(\"relu\")(conv)\n    conv = Conv2D(filters, kernel_size = (3,3), padding=\"same\")(bn)\n    bn = BatchNormalization(axis=3)(conv)\n    bn = Activation(\"relu\")(bn)\n    pool = MaxPooling2D(pool_size=(2, 2))(bn)\n\n    return conv, pool;\n\ndef decoder_block(inputs, conv, num_filters):\n  conv_trans = Conv2DTranspose(num_filters, kernel_size= (2,2), strides = (2,2), padding = \"same\")(inputs)\n\n  x = concatenate([conv_trans, conv], axis = 3)\n  x = Conv2D(num_filters, kernel_size = (3,3), padding= \"same\")(x)\n  x = Activation(\"relu\")(x)\n  x = Conv2D(num_filters, kernel_size = (3,3), padding = \"same\")(x)\n  x = BatchNormalization(axis = 3)(x)\n  x = Activation('relu')(x)\n\n  return x ;\n\n\n\n","metadata":{"id":"4gg2oj7Cp6xG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining the U-Net Architecture","metadata":{"id":"7-Pcna3vx9gl"}},{"cell_type":"code","source":"def unet_model(input_shape = (img_width, img_height, 3)):\n  inputs = Input(input_shape)\n\n  #Contracting paths ( Encoder Path) / Downsampling\n\n  conv1, pool1 = encoder_block( inputs, 64)\n  conv2, pool2 = encoder_block(pool1, 128)\n  conv3, pool3 = encoder_block(pool2, 256)\n  conv4, pool4 = encoder_block(pool3, 512)\n\n\n  # Bottleneck\n  b1 = Conv2D(filters = 1024, kernel_size = (3,3), padding = 'same')(pool4)\n  b1 = Activation('relu')(b1)\n  b1 = Conv2D(filters = 1024, kernel_size = (3,3), padding = 'same')(b1)\n  b1 = BatchNormalization(axis = 3)(b1)\n  b1 = Activation('relu')(b1)\n\n  #Expansive path ( Decoder path) / UpSampling\n\n  s5 = decoder_block(b1, conv4, 512)\n  s6 = decoder_block(s5, conv3, 256)\n  s7 = decoder_block(s6, conv2, 128)\n  s8 = decoder_block(s7, conv1 , 64)\n\n\n  #Output\n  outputs = Conv2D(filters = 1, kernel_size = (1,1), activation = \"sigmoid\")(s8)\n\n  return Model(inputs=[inputs], outputs = [outputs])","metadata":{"id":"F_qwWl2Sx7_z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## training parameters and augmentation dictionary","metadata":{"id":"egtu_3Ir5sl8"}},{"cell_type":"code","source":"epochs = 5\nbatch_size = 32\nlr = 1e-4\n\ntrain_generator_args = dict(\n    rotation_range = 0.25,\n    width_shift_range = 0.05,\n    height_shift_range=0.05,\n    shear_range=0.05,\n    zoom_range=0.05,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\ntrain_gen  = train_generator( df_train, batch_size, train_generator_args)\ntest_gen = train_generator(df_test, batch_size, dict() )\n\n\nmodel = unet_model(input_shape =(256,256, 3))\noptimizer = Adam(lr = lr , beta_1 = 0.9, beta_2 = 0.999, epsilon = None, amsgrad = False)\n\n\nmodel.compile(optimizer=optimizer, loss=dice_coefficients_loss, metrics=[\"binary_accuracy\", iou, dice_coefficients])\ncallbacks = [\n    ModelCheckpoint('unet_model.hdf5',verbose=1, save_best_only=True )\n]\n\nhistory = model.fit(\n      train_gen,\n      steps_per_epoch = len(df_train) / batch_size,\n      epochs = epochs,\n      callbacks = callbacks,\n      validation_data = test_gen,\n      validation_steps = len(df_valid) / batch_size\n)","metadata":{"id":"g4eIsez75uws","outputId":"99cd53a9-f5c7-4b2c-fa2b-cbde105aa8c8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model, to_file = \"Model.png\", show_shapes=True)\n","metadata":{"id":"5WWQuCQK-QcA","outputId":"75d476a9-5ce3-4e81-c5c2-76aa3bc39570","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_training = history.history\n\ntrain_dice_coeff_list = history_training['dice_coefficients']\ntest_dice_coeff_list = history_training['val_dice_coefficients']\n\ntrain_jaccard_list = history_training['iou']\ntest_jaccard_list = history_training['val_iou']\n\ntrain_loss_list = history_training['loss']\ntest_loss_list = history_training['val_loss']\n\n\nplt.plot(test_loss_list, 'b-', label='Test Loss')\nplt.plot(train_loss_list, 'r-', label='Train Loss')\n\nplt.xlabel('iterations')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize=12)\nplt.legend()\nplt.show()\nplt.savefig('Loss Graph')","metadata":{"id":"4-RT2_dYFEuT","outputId":"930abc8a-14c2-4dc0-d9d6-1e55c3ce5572","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_dice_coeff_list, 'b-', label='Train Accuracy')\nplt.plot(test_dice_coeff_list, 'r-', label = 'Test Accuracy')\n\nplt.xlabel('iterations')\nplt.ylabel('accuracy')\nplt.title('Accuracy graph', fontsize=12)\nplt.legend()\nplt.show()\nplt.savefig('Accuracy Graph')","metadata":{"id":"JWgPnzPQsMd3","outputId":"faecab0f-5ccd-436d-e1ab-fccb7727436d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('unet_model.hdf5', custom_objects={'dice_coefficients_loss': dice_coefficients_loss, 'iou': iou, 'dice_coefficients': dice_coefficients})","metadata":{"id":"KIl_jS09FKBy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen = train_generator(df_test, batch_size, dict(), target_size=(img_height,img_width))\n\nresults = model.evaluate(test_gen, steps = len(df_test)/batch_size)\nprint('Test Loss', results[0])\nprint('Test IOU', results[1])\nprint('Test Dice Coeff', results[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfor i in range(20):\n    index = np.random.randint(1, len(df_test.index))\n    img = cv2.imread(df_test['images_train'].iloc[index])\n    img = cv2.resize(img, (img_height,img_width))\n    img = img/255\n    img = img[np.newaxis, : ,:, :]\n    pred_img = model.predict(img)\n    \n    plt.figure(figsize=(12,12))\n    plt.subplot(1, 3, 1)\n    plt.imshow(np.squeeze(img))\n    plt.title(\"Original Image\")\n    plt.subplot(1, 3, 2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['masks'].iloc[index])))\n    plt.title(\"Original Mask\")\n    plt.subplot(1, 3, 3)\n    plt.imshow(np.squeeze(pred_img) > 0.5)\n    plt.title(\"Prediction\")\n    plt.show()\n    plt.savefig('Originals vs Predictions')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(history.history) \n\n# save to json:  \nhist_json_file = 'history.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)\n\n# or save to csv: \nhist_csv_file = 'history.csv'\nwith open(hist_csv_file, mode='w') as f:\n    hist_df.to_csv(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\ncm = confusion_matrix(y_true.flatten(), y_pred.flatten())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}